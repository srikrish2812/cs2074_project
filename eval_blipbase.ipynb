{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7762bc-bfee-461b-817b-26dbf84a4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, AutoTokenizer, AutoModel\n",
    "from sacrebleu import corpus_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca1640ca-8bcd-4f09-be43-83602489f239",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sacrebleu\n",
      "  Using cached sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "Requirement already satisfied: portalocker in ./.local/lib/python3.11/site-packages (from sacrebleu) (3.2.0)\n",
      "Requirement already satisfied: regex in /ix/cs2731_2025f/class_env/lib/python3.11/site-packages (from sacrebleu) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in ./.local/lib/python3.11/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /ix/cs2731_2025f/class_env/lib/python3.11/site-packages (from sacrebleu) (1.26.4)\n",
      "Requirement already satisfied: colorama in /ix/cs2731_2025f/class_env/lib/python3.11/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in ./.local/lib/python3.11/site-packages (from sacrebleu) (6.0.2)\n",
      "Using cached sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "Installing collected packages: sacrebleu\n",
      "Successfully installed sacrebleu-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fedb606-72f6-4931-8ddf-5b090537899f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: rouge_score in ./.local/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /ix/cs2731_2025f/class_env/lib/python3.11/site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in /ix/cs2731_2025f/class_env/lib/python3.11/site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /ix/cs2731_2025f/class_env/lib/python3.11/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /ix/cs2731_2025f/class_env/lib/python3.11/site-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /ix/cs2731_2025f/class_env/lib/python3.11/site-packages (from nltk->rouge_score) (8.2.1)\n",
      "Requirement already satisfied: joblib in /ix/cs2731_2025f/class_env/lib/python3.11/site-packages (from nltk->rouge_score) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /ix/cs2731_2025f/class_env/lib/python3.11/site-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /ix/cs2731_2025f/class_env/lib/python3.11/site-packages (from nltk->rouge_score) (4.67.1)\n",
      "/bin/bash: line 1: bert_score: command not found\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score; bert_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87d185a3-2272-47d2-8536-b95272645663",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Fakhraddin/NLMCXR\")\n",
    "split_to_use = \"validation\"  # or \"train\", can also combine\n",
    "data = dataset[split_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec9ef476-11bc-4ea4-b308-09d75bbd7676",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BlipForConditionalGeneration(\n",
       "  (vision_model): BlipVisionModel(\n",
       "    (embeddings): BlipVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (encoder): BlipEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (text_decoder): BlipTextLMHeadModel(\n",
       "    (bert): BlipTextModel(\n",
       "      (embeddings): BlipTextEmbeddings(\n",
       "        (word_embeddings): Embedding(30524, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (encoder): BlipTextEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BlipTextLayer(\n",
       "            (attention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BlipTextIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BlipTextOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BlipTextOnlyMLMHead(\n",
       "      (predictions): BlipTextLMPredictionHead(\n",
       "        (transform): BlipTextPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (transform_act_fn): GELUActivation()\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=30524, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16b9fe37-54b9-42cc-aa03-bba7bc3b5f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating captions: 100%|██████████| 1505/1505 [02:52<00:00,  8.72it/s]\n"
     ]
    }
   ],
   "source": [
    "preds, refs = [], []\n",
    "\n",
    "for example in tqdm(data, desc=\"Generating captions\"):\n",
    "    image = example[\"image\"]\n",
    "    ref_text = example[\"text\"] \n",
    "    \n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=50)\n",
    "    \n",
    "    pred = processor.decode(output[0], skip_special_tokens=True)\n",
    "    preds.append(pred)\n",
    "    refs.append(ref_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df076014-a70b-42df-bf34-f72eb94777d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Cosine Similarity: 0.6542\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "bert_model.eval()\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    emb = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()  # CLS token\n",
    "    return emb\n",
    "\n",
    "cosines = []\n",
    "for p, r in zip(preds, refs):\n",
    "    e1, e2 = get_embedding(p), get_embedding(r)\n",
    "    cos = np.dot(e1, e2) / (np.linalg.norm(e1) * np.linalg.norm(e2))\n",
    "    cosines.append(cos)\n",
    "\n",
    "avg_cosine = np.mean(cosines)\n",
    "print(f\"Avg. Cosine Similarity: {avg_cosine:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f49b8c37-05bc-4f55-bae6-beceb00c3fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. BLEU: 0.0054\n"
     ]
    }
   ],
   "source": [
    "avg_bleu = corpus_bleu(preds, [refs]).score\n",
    "print(f\"Avg. BLEU: {avg_bleu:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84789a69-affa-454b-b2c4-916b1bf7570b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. ROUGE-1: 0.0344\n",
      "Avg. ROUGE-2: 0.0022\n",
      "Avg. ROUGE-L: 0.0326\n"
     ]
    }
   ],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "rouge1s, rouge2s, rougeLs = [], [], []\n",
    "for r, p in zip(refs, preds):\n",
    "    s = scorer.score(r, p)\n",
    "    rouge1s.append(s['rouge1'].fmeasure)\n",
    "    rouge2s.append(s['rouge2'].fmeasure)\n",
    "    rougeLs.append(s['rougeL'].fmeasure)\n",
    "avg_rouge1 = np.mean(rouge1s)\n",
    "avg_rouge2 = np.mean(rouge2s)\n",
    "avg_rougeL = np.mean(rougeLs)\n",
    "\n",
    "print(f\"Avg. ROUGE-1: {avg_rouge1:.4f}\")\n",
    "print(f\"Avg. ROUGE-2: {avg_rouge2:.4f}\")\n",
    "print(f\"Avg. ROUGE-L: {avg_rougeL:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8fc3079-4822-45f1-a973-ddc14cbbe814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. BERTScore (F1): 0.3781\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# Load metric\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Compute BERTScore\n",
    "results = bertscore.compute(predictions=preds, references=refs, model_type=\"bert-base-uncased\")\n",
    "\n",
    "# Get average F1 score\n",
    "avg_bertscore = sum(results[\"f1\"]) / len(results[\"f1\"])\n",
    "\n",
    "print(f\"Avg. BERTScore (F1): {avg_bertscore:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf4a1601-7f43-44fc-8a97-39b83bddc6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Final Evaluation Metrics (BLIP Base + NLMCXR) =====\n",
      "Avg. Cosine Similarity: 0.6542\n",
      "Avg. BLEU:              0.0054\n",
      "Avg. ROUGE-1:           0.0344\n",
      "Avg. ROUGE-2:           0.0022\n",
      "Avg. ROUGE-L:           0.0326\n",
      "Avg. BERTScore (F1):    0.3781\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Final Evaluation Metrics (BLIP Base + NLMCXR) =====\")\n",
    "print(f\"Avg. Cosine Similarity: {avg_cosine:.4f}\")\n",
    "print(f\"Avg. BLEU:              {avg_bleu:.4f}\")\n",
    "print(f\"Avg. ROUGE-1:           {avg_rouge1:.4f}\")\n",
    "print(f\"Avg. ROUGE-2:           {avg_rouge2:.4f}\")\n",
    "print(f\"Avg. ROUGE-L:           {avg_rougeL:.4f}\")\n",
    "print(f\"Avg. BERTScore (F1):    {avg_bertscore:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6391cc8-ead3-4f3c-a3d5-7d782617771a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
